{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Evaluations - Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_data = pd.read_csv('questionnaire\\\\long_term\\\\response_summary_long.csv')\n",
    "resp_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'method' and compute mean and std of 'score'\n",
    "grouped_data = resp_data.groupby('method')['score'].agg(['mean', 'std'])\n",
    "\n",
    "# Perform ANOVA test\n",
    "anova_result = f_oneway(*[group['score'] for name, group in resp_data.groupby('method')])\n",
    "\n",
    "# Print the mean and std of 'score' for each 'method'\n",
    "print(\"Mean and Standard Deviation of 'score' by 'method':\")\n",
    "print(grouped_data)\n",
    "\n",
    "# Print the ANOVA test result\n",
    "print(\"\\nANOVA Test Result:\")\n",
    "print(\"F-value:\", anova_result.statistic)\n",
    "print(\"p-value:\", anova_result.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='strategy', y='score', hue='method', data=resp_data, palette='viridis')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Scores by Strategy and Method')\n",
    "plt.xlabel('Strategy')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shirley's Method\n",
    "\n",
    "for each participant {\n",
    "    baseline_score_g = mean(method==0, G);\n",
    "    baseline_score_o = mean(method==0, O);\n",
    "    for each passage whose method == 1 {\n",
    "        do pair t-test between the score (compare the score and the corresponding baseline, decided by G or O)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add overall recall and theme recall\n",
    "\n",
    "recall: overall recall\n",
    "\n",
    "theme: the question 6\n",
    "\n",
    "overall: the total score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Step 1: Load the data and split by method\n",
    "df = pd.read_csv('/Users/fukexue/film_learning_study3/final score with all data.csv')\n",
    "\n",
    "# Split into two dataframes based on method\n",
    "df_method_0 = df[df['method'] == 0]\n",
    "df_method_1 = df[df['method'] == 1]\n",
    "\n",
    "# Function to compute baseline scores\n",
    "def compute_baseline(df_method_0, column_name):\n",
    "    baseline_scores = df_method_0.groupby(['participant', 'corpus'])[column_name].mean().reset_index()\n",
    "    baseline_scores.rename(columns={column_name: f'baseline_{column_name}'}, inplace=True)\n",
    "    return baseline_scores\n",
    "\n",
    "# Compute baseline scores for 'score', 'recall', and 'theme'\n",
    "baseline_withcues = compute_baseline(df_method_0, 'withcues')\n",
    "baseline_withoutcues = compute_baseline(df_method_0, 'withoutcues')\n",
    "\n",
    "\n",
    "# Merge the baseline scores with method==1 dataframe\n",
    "df_method_1_merged = pd.merge(df_method_1, baseline_withcues, on=['participant', 'corpus'])\n",
    "df_method_1_merged = pd.merge(df_method_1_merged, baseline_withoutcues, on=['participant', 'corpus'])\n",
    "\n",
    "\n",
    "# Function to perform t-test and print results\n",
    "def perform_t_test(df_method_1_merged, column_name):\n",
    "    t_stat, p_value = ttest_rel(df_method_1_merged[column_name], df_method_1_merged[f'baseline_{column_name}'])\n",
    "    average_score_method_0 = df_method_0[column_name].mean()\n",
    "    average_score_method_1 = df_method_1_merged[column_name].mean()\n",
    "    print(f\"Average {column_name} for method 0:\", average_score_method_0)\n",
    "    print(f\"Average {column_name} for method 1:\", average_score_method_1)\n",
    "    print(f\"T-statistic for {column_name}:\", t_stat)\n",
    "    print(f\"P-value for {column_name}:\", p_value)\n",
    "    print('\\n')\n",
    "\n",
    "# Perform t-tests for 'score', 'recall', and 'theme'\n",
    "for column in ['withcues', 'withoutcues']:\n",
    "    perform_t_test(df_method_1_merged, column)\n",
    "\n",
    "# Save the merged dataframe with baseline columns to a single CSV file\n",
    "df_method_1_merged.to_csv('questionnaire/long_term/t-test_results.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Function to perform t-test and store results\n",
    "def perform_t_test_by_corpus(df_method_1_merged, column_name):\n",
    "    grouped = df_method_1_merged.groupby('corpus')\n",
    "    for corpus_name, group in grouped:\n",
    "        t_stat, p_value = ttest_rel(group[column_name], group[f'baseline_{column_name}'])\n",
    "        average_score_method_0 = df_method_0[df_method_0['corpus'] == corpus_name][column_name].mean()\n",
    "        average_score_method_1 = group[column_name].mean()\n",
    "        \n",
    "        # Store the results in the list\n",
    "        results.append({\n",
    "            'corpus': corpus_name,\n",
    "            'metric': column_name,\n",
    "            'average_method_0': average_score_method_0,\n",
    "            'average_method_1': average_score_method_1,\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "\n",
    "# Perform t-tests for 'score', 'recall', 'theme', and 'overall' grouped by corpus\n",
    "for column in ['withcues', ' withoutcues']:\n",
    "    perform_t_test_by_corpus(df_method_1_merged, column)\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Output the results DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and P value calculation for each strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "\n",
    "# Load the uploaded CSV data\n",
    "file_path = 'questionnaire/long_term/response_summary_long.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract unique strategies\n",
    "strategies = data['strategy'].unique()\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Iterate over each strategy and column of interest\n",
    "for strategy in strategies:\n",
    "    strategy_data = data[data['strategy'] == strategy]\n",
    "    results[strategy] = {}\n",
    "    \n",
    "    for column in ['score', 'recall', 'theme', 'overall']:\n",
    "        results[strategy][column] = {}\n",
    "        \n",
    "        # Prepare data for ANOVA\n",
    "        method_groups = [strategy_data[strategy_data['method'] == method][column].values for method in strategy_data['method'].unique()]\n",
    "        \n",
    "        # Perform one-way ANOVA\n",
    "        f_stat, p_value = stats.f_oneway(*method_groups)\n",
    "        \n",
    "        # Store results in dictionary\n",
    "        results[strategy][column] = {\n",
    "            'f_stat': f_stat,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "        \n",
    "        # Plotting for each column\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        boxplot_data = method_groups\n",
    "        labels = [f'Method {method}' for method in strategy_data['method'].unique()]\n",
    "        \n",
    "        ax.boxplot(boxplot_data, labels=labels, patch_artist=True)\n",
    "        plt.xlabel('Method')\n",
    "        plt.ylabel(column.capitalize())\n",
    "        plt.title(f'{column.capitalize()} Comparison within {strategy} (ANOVA)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Optionally, save the results to a JSON file\n",
    "output_file = '/Users/fukexue/film_learning_study3/questionnaire/long_term/strategy_comparison_anova_results.json'\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "# Print the results dictionary for review\n",
    "print(json.dumps(results, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final data： To test repeated measure anova with strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import json\n",
    "\n",
    "# Load the uploaded CSV data\n",
    "file_path = 'final score with all data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract unique strategies\n",
    "strategies = data['strategy'].unique()\n",
    "\n",
    "# Initialize dictionary to store ANOVA results and means of method 0 and method 1\n",
    "results = {}\n",
    "\n",
    "# Prepare subplots for combined visualization\n",
    "fig, axs = plt.subplots(2, 1, figsize=(16, 12))\n",
    "columns = ['withoutcues', 'withcues']\n",
    "axes = axs.flatten()\n",
    "\n",
    "# Iterate over each column of interest\n",
    "for i, column in enumerate(columns):\n",
    "    results[column] = {}\n",
    "    \n",
    "    # Prepare data for plotting and analysis\n",
    "    combined_data = []\n",
    "    labels = []\n",
    "\n",
    "    for strategy in strategies:\n",
    "        strategy_data = data[data['strategy'] == strategy]\n",
    "        \n",
    "        # Reformat the data for ANOVA\n",
    "        long_format_data = pd.melt(strategy_data, id_vars=['participant', 'strategy', 'method'], value_vars=[column],\n",
    "                                  var_name='variable', value_name='value')\n",
    "        \n",
    "        # Perform Repeated Measures ANOVA\n",
    "        model = AnovaRM(long_format_data, 'value', 'participant', within=['method'])\n",
    "        results[column][strategy] = model.fit()\n",
    "        \n",
    "        # Prepare data for boxplot\n",
    "        combined_data.append(strategy_data[strategy_data['method'] == 0][column].values)\n",
    "        combined_data.append(strategy_data[strategy_data['method'] == 1][column].values)\n",
    "        labels.append(f'{strategy} (Method 0)')\n",
    "        labels.append(f'{strategy} (Method 1)')\n",
    "    \n",
    "    # Plotting combined boxplot for each column\n",
    "    axes[i].boxplot(combined_data, labels=labels, patch_artist=True)\n",
    "    axes[i].set_title(f'{column.capitalize()} across all Strategies')\n",
    "    axes[i].set_xlabel('Strategy and Method')\n",
    "    axes[i].set_ylabel(column.capitalize())\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the combined results dictionary with means and ANOVA results\n",
    "anova_results = {}\n",
    "for column, strategy_results in results.items():\n",
    "    anova_results[column] = {}\n",
    "    for strategy, result in strategy_results.items():\n",
    "        anova_results[column][strategy] = {\n",
    "            'anova_table': result.summary().as_text()\n",
    "        }\n",
    "\n",
    "print(json.dumps(anova_results, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final data To test repeated measure(one way) anova on each material "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "\n",
    "# Load the uploaded CSV data\n",
    "file_path = 'final score with all data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract unique topics\n",
    "topics = data['topic'].unique()\n",
    "\n",
    "# Initialize dictionary to store ANOVA results and p-values\n",
    "results = {}\n",
    "\n",
    "# Prepare subplots for combined visualization\n",
    "fig, axs = plt.subplots(2, 1, figsize=(18, 12))\n",
    "columns = ['withoutcues', 'withcues']\n",
    "axes = axs.flatten()\n",
    "\n",
    "# Iterate over each dimension (column)\n",
    "for i, column in enumerate(columns):\n",
    "    all_combined_data = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Initialize results for this column\n",
    "    if column not in results:\n",
    "        results[column] = {}\n",
    "    \n",
    "    for topic in topics:\n",
    "        topic_data = data[data['topic'] == topic]\n",
    "        \n",
    "        # Perform One-Way ANOVA without considering participant\n",
    "        try:\n",
    "            model = sm.formula.ols(f'{column} ~ C(method)', data=topic_data).fit()\n",
    "            anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "            p_value = anova_table['PR(>F)']['C(method)']\n",
    "            results[column][topic] = {\n",
    "                'anova_table': anova_table.to_string(),\n",
    "                'p_value': p_value\n",
    "            }\n",
    "        except Exception as e:\n",
    "            results[column][topic] = {\n",
    "                'anova_table': str(e),\n",
    "                'p_value': 'nan'\n",
    "            }\n",
    "\n",
    "        # Prepare data for plotting\n",
    "        method_0_data = topic_data[topic_data['method'] == 0][column].values\n",
    "        method_1_data = topic_data[topic_data['method'] == 1][column].values\n",
    "        \n",
    "        all_combined_data.append(method_0_data)\n",
    "        all_combined_data.append(method_1_data)\n",
    "        all_labels.append(f'{topic} Method 0')\n",
    "        all_labels.append(f'{topic} Method 1')\n",
    "    \n",
    "    # Plotting combined boxplot for each column\n",
    "    axes[i].boxplot(all_combined_data, labels=all_labels, patch_artist=True)\n",
    "    axes[i].set_title(f'{column.capitalize()} Across Topics')\n",
    "    axes[i].set_xlabel('Topic and Method')\n",
    "    axes[i].set_ylabel(column.capitalize())\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Output the results with p-values\n",
    "results_json = json.dumps(results, indent=4)\n",
    "\n",
    "# Extract and print p-values for each topic\n",
    "for column in columns:\n",
    "    print(f\"\\nP-values for '{column}':\")\n",
    "    if column in results:\n",
    "        for topic in topics:\n",
    "            p_value = results[column].get(topic, {}).get('p_value', 'nan')\n",
    "            print(f\"{topic}: {p_value}\")\n",
    "\n",
    "# Print the full results JSON\n",
    "results_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic‘s influence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# 假设数据已加载\n",
    "file_path = 'questionnaire/long_term/response_summary_long.csv'  # 替换为您的文件路径\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 要分析的四个维度\n",
    "dimensions = ['score', 'recall', 'theme', 'overall']\n",
    "\n",
    "# 循环分析每个维度\n",
    "for dimension in dimensions:\n",
    "    print(f\"\\nAnalysis for {dimension}:\")\n",
    "\n",
    "    # 创建线性回归模型，评估 topic 的影响\n",
    "    model = ols(f'{dimension} ~ topic', data=data).fit()\n",
    "    \n",
    "    # 生成 ANOVA 表\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    print(f\"ANOVA results for {dimension}:\")\n",
    "    print(anova_table)\n",
    "\n",
    "    # 执行 Tukey HSD 测试，进一步分析 topic 的影响\n",
    "    print(f\"\\nTukey HSD results for {dimension}:\")\n",
    "    tukey = pairwise_tukeyhsd(endog=data[dimension], groups=data['topic'], alpha=0.05)\n",
    "    print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method=0 or method=1' tukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'questionnaire/long_term/response_summary_long.csv'  # 替换为您的文件路径\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 要分析的四个维度\n",
    "dimensions = ['score', 'recall', 'theme', 'overall']\n",
    "\n",
    "# 分别针对 method=0 和 method=1 进行分析\n",
    "methods = [0, 1]\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\nANOVA and Tukey HSD analysis for method={method}:\")\n",
    "\n",
    "    # 过滤数据只保留当前 method 的情况\n",
    "    method_data = data[data['method'] == method]\n",
    "    \n",
    "    for dimension in dimensions:\n",
    "        print(f\"\\nAnalyzing {dimension} (Method = {method}):\")\n",
    "        \n",
    "        # ANOVA 分析\n",
    "        model = ols(f'{dimension} ~ C(topic)', data=method_data).fit()\n",
    "        anova_table = anova_lm(model, typ=2)\n",
    "        print(\"ANOVA results:\")\n",
    "        print(anova_table)\n",
    "        \n",
    "        # 提取p值\n",
    "        p_value = anova_table[\"PR(>F)\"][0]\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        \n",
    "        # 如果 ANOVA 结果显示 topic 的影响显著（p值小于0.05），进行 Tukey HSD 分析\n",
    "        if p_value < 0.05:\n",
    "            print(f\"\\nTukey HSD results for {dimension} (Method = {method}):\")\n",
    "            tukey = pairwise_tukeyhsd(endog=method_data[dimension], groups=method_data['topic'], alpha=0.05)\n",
    "            print(tukey.summary())\n",
    "        else:\n",
    "            print(f\"No significant effect of topic on {dimension} (Method = {method}). Skipping Tukey HSD analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short term results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Step 1: Load the data and split by method\n",
    "df = pd.read_csv('questionnaire/short_term/response_summary.csv')  # Replace with your CSV file path\n",
    "\n",
    "# Split into two dataframes based on method\n",
    "df_method_0 = df[df['method'] == 0]\n",
    "df_method_1 = df[df['method'] == 1]\n",
    "\n",
    "# Function to compute baseline scores\n",
    "def compute_baseline(df_method_0, column_name):\n",
    "    baseline_scores = df_method_0.groupby(['participant', 'corpus'])[column_name].mean().reset_index()\n",
    "    baseline_scores.rename(columns={column_name: f'baseline_{column_name}'}, inplace=True)\n",
    "    return baseline_scores\n",
    "\n",
    "# List of columns to perform t-tests on\n",
    "columns_to_test = [\n",
    "    'score', 'competence', 'activity', 'frustration', 'pleasure', 'pressure', \n",
    "    'effort', 'immersion', 'physicality', 'difficulty', 'familarity', 'understanding'\n",
    "]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Function to perform t-test and store results by corpus\n",
    "def perform_t_test_by_corpus(df_method_1_merged, column_name):\n",
    "    grouped = df_method_1_merged.groupby('corpus')\n",
    "    for corpus_name, group in grouped:\n",
    "        t_stat, p_value = ttest_rel(group[column_name], group[f'baseline_{column_name}'])\n",
    "        average_score_method_0 = df_method_0[df_method_0['corpus'] == corpus_name][column_name].mean()\n",
    "        average_score_method_1 = group[column_name].mean()\n",
    "        \n",
    "        # Store the results in the list\n",
    "        results.append({\n",
    "            'corpus': corpus_name,\n",
    "            'metric': column_name,\n",
    "            'average_method_0': average_score_method_0,\n",
    "            'average_method_1': average_score_method_1,\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "\n",
    "# Perform t-tests for each column grouped by corpus\n",
    "for column in columns_to_test:\n",
    "    # Compute baseline scores for the current column\n",
    "    baseline_score = compute_baseline(df_method_0, column)\n",
    "    \n",
    "    # Merge the baseline scores with method==1 dataframe\n",
    "    df_method_1_merged = pd.merge(df_method_1, baseline_score, on=['participant', 'corpus'])\n",
    "    \n",
    "    # Perform t-test for the current column grouped by corpus\n",
    "    perform_t_test_by_corpus(df_method_1_merged, column)\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Output the results DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv('questionnaire/short_term/t-test_results_all_columns.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "\n",
    "# 读取CSV数据到DataFrame\n",
    "data = pd.read_csv('questionnaire/short_term/t-test_results.csv')\n",
    "\n",
    "# 提取感兴趣的列\n",
    "columns_of_interest = [\n",
    "   'score', 'competence', 'activity', 'frustration', 'pleasure', 'pressure', \n",
    "    'effort', 'immersion', 'physicality', 'difficulty', 'familarity', 'understanding'\n",
    "]\n",
    "\n",
    "# 提取各策略的唯一值\n",
    "strategies = data['strategy'].unique()\n",
    "results = {}\n",
    "\n",
    "# 对每个感兴趣的列进行迭代\n",
    "for column in columns_of_interest:\n",
    "    boxplot_data = []\n",
    "    labels = []\n",
    "    results[column] = {}\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        strategy_data = data[data['strategy'] == strategy]\n",
    "        \n",
    "        # 提取基准数据和策略数据\n",
    "        baseline_data = strategy_data['baseline_' + column].values\n",
    "        strategy_data_values = strategy_data[column].values\n",
    "        \n",
    "        # 计算均值\n",
    "        baseline_mean = baseline_data.mean()\n",
    "        strategy_mean = strategy_data_values.mean()\n",
    "        \n",
    "        # 进行配对t检验以获得p值\n",
    "        t_stat, p_value = stats.ttest_rel(baseline_data, strategy_data_values)\n",
    "        \n",
    "        # 将结果存储到字典中\n",
    "        results[column][strategy] = {\n",
    "            'baseline_mean': baseline_mean,\n",
    "            'strategy_mean': strategy_mean,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "        \n",
    "        # 为箱线图准备数据\n",
    "        boxplot_data.append(baseline_data)\n",
    "        boxplot_data.append(strategy_data_values)\n",
    "        labels.append(f'{strategy} baseline')\n",
    "        labels.append(f'{strategy} w/ strategy')\n",
    "    \n",
    "    # 绘图\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.boxplot(boxplot_data, labels=labels, patch_artist=True)\n",
    "\n",
    "    plt.xlabel('Strategy')\n",
    "    plt.ylabel(column.capitalize())\n",
    "    plt.title(f'{column.capitalize()} of Baseline vs. Strategy')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 可选：将结果保存到JSON文件\n",
    "with open('strategy_results.json', 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "# 打印结果字典以供查看\n",
    "print(json.dumps(results, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
